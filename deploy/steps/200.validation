#!/bin/bash

# ==============================================
# Step 200: Deployment Validation
# ==============================================

set -e

log "Deployment Validation"

APP_DIR="$HOME/zerogex-oa"
PGPASS_FILE="$HOME/.pgpass"

# Parse RDS connection details from .pgpass
if [ -f "$PGPASS_FILE" ]; then
    DB_HOST=$(cat "$PGPASS_FILE" | awk -F: '{print $1}')
    DB_PORT=$(cat "$PGPASS_FILE" | awk -F: '{print $2}')
    DB_NAME=$(cat "$PGPASS_FILE" | awk -F: '{print $3}')
    DB_USER=$(cat "$PGPASS_FILE" | awk -F: '{print $4}')
else
    log "  ✗ .pgpass file not found at $PGPASS_FILE"
    log "     Cannot determine database connection parameters"
    exit 1
fi

# Validation results tracking
TOTAL_CHECKS=0
PASSED_CHECKS=0
FAILED_CHECKS=0
WARNING_CHECKS=0

# Check function
check_service() {
    TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
    local service_name=$1
    local display_name=$2

    if systemctl is-active --quiet "$service_name"; then
        log "  ✓ $display_name: $(systemctl is-active "$service_name")"
        PASSED_CHECKS=$((PASSED_CHECKS + 1))
        return 0
    else
        log "  ✗ $display_name: $(systemctl is-active "$service_name")"
        FAILED_CHECKS=$((FAILED_CHECKS + 1))
        return 1
    fi
}

# Section 1: Service Status
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "1. Service Status Checks"
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
check_service "zerogex-oa-ingestion" "Ingestion Service"
check_service "zerogex-oa-analytics" "Analytics Service"
check_service "zerogex-oa-api" "API Service"
log ""

# Section 2: Database Connection
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "2. Database Connection Test (AWS RDS)"
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "  Connection Details:"
log "    Host: $DB_HOST"
log "    Port: $DB_PORT"
log "    Database: $DB_NAME"
log "    User: $DB_USER"
log ""
TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
if psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "SELECT NOW();" > /dev/null 2>&1; then
    DB_TIME=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT NOW();")
    log "  ✓ Database connection successful"
    log "     Database time: $DB_TIME"
    PASSED_CHECKS=$((PASSED_CHECKS + 1))
else
    log "  ✗ Database connection failed"
    log "     Check RDS security group settings"
    log "     Ensure EC2 instance can connect to RDS"
    FAILED_CHECKS=$((FAILED_CHECKS + 1))
fi
log ""

# Section 3: Database Tables
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "3. Database Schema Validation"
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

TABLES=(
    "symbols"
    "underlying_quotes"
    "option_chains"
    "gex_summary"
    "gex_by_strike"
    "data_quality_log"
    "ingestion_metrics"
    "data_retention_policy"
)

for table in "${TABLES[@]}"; do
    TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
    if psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "\dt $table" 2>/dev/null | grep -q "$table"; then
        log "  ✓ Table exists: $table"
        PASSED_CHECKS=$((PASSED_CHECKS + 1))
    else
        log "  ⚠ Table not found: $table"
        WARNING_CHECKS=$((WARNING_CHECKS + 1))
    fi
done
log ""

# Section 4: Views
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "4. Database Views (Real-Time)"
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

VIEWS=(
    "underlying_quotes_with_deltas"
    "option_chains_with_deltas"
    "option_flow_by_type"
    "option_flow_by_strike"
    "option_flow_by_expiration"
    "option_flow_smart_money"
    "underlying_buying_pressure"
    "underlying_vwap_deviation"
    "opening_range_breakout"
    "gamma_exposure_levels"
    "dealer_hedging_pressure"
    "unusual_volume_spikes"
    "momentum_divergence"
)

for view in "${VIEWS[@]}"; do
    TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
    if psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "\dv $view" 2>/dev/null | grep -q "$view"; then
        log "  ✓ View exists: $view"
        PASSED_CHECKS=$((PASSED_CHECKS + 1))
    else
        log "  ⚠ View not found: $view"
        WARNING_CHECKS=$((WARNING_CHECKS + 1))
    fi
done
log ""

# Section 5: Data Retention Configuration
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "5. Data Retention Configuration"
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
RETENTION_COUNT=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM data_retention_policy WHERE enabled = true;" 2>/dev/null | xargs || echo "0")
if [ "$RETENTION_COUNT" -gt 0 ]; then
    log "  ✓ Data retention policies configured: $RETENTION_COUNT active"
    PASSED_CHECKS=$((PASSED_CHECKS + 1))

    # Show retention policies
    log ""
    log "  Active Retention Policies:"
    psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "SELECT table_name, retention_days, last_cleanup FROM data_retention_policy WHERE enabled = true ORDER BY table_name;" 2>/dev/null || true
else
    log "  ⚠ No data retention policies found"
    WARNING_CHECKS=$((WARNING_CHECKS + 1))
fi
log ""

# Section 6: Cron Job
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "6. Data Retention Cron Job"
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
if crontab -l 2>/dev/null | grep -q "cleanup_old_data"; then
    log "  ✓ Cleanup cron job configured"
    PASSED_CHECKS=$((PASSED_CHECKS + 1))
    log ""
    log "  Cron Job Details:"
    crontab -l 2>/dev/null | grep "cleanup_old_data" || true
else
    log "  ✗ Cleanup cron job not found"
    FAILED_CHECKS=$((FAILED_CHECKS + 1))
fi
log ""

# Section 7: Python Environment
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "7. Python Environment"
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
if [ -d "$APP_DIR/venv" ]; then
    log "  ✓ Virtual environment exists"
    PASSED_CHECKS=$((PASSED_CHECKS + 1))

    # Check key packages
    cd "$APP_DIR"
    source venv/bin/activate

    PACKAGES=("psycopg2" "pandas" "numpy" "scipy" "requests" "pytz" "fastapi" "uvicorn" "asyncpg" "pydantic")
    for package in "${PACKAGES[@]}"; do
        TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
        if python -c "import $package" 2>/dev/null; then
            log "  ✓ Package installed: $package"
            PASSED_CHECKS=$((PASSED_CHECKS + 1))
        else
            log "  ✗ Package missing: $package"
            FAILED_CHECKS=$((FAILED_CHECKS + 1))
        fi
    done

    deactivate
else
    log "  ✗ Virtual environment not found"
    FAILED_CHECKS=$((FAILED_CHECKS + 1))
fi
log ""

# Section 8: Configuration Files
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "8. Configuration Files"
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

CONFIG_FILES=(
    "$HOME/.pgpass"
    "$APP_DIR/.env"
)

for config_file in "${CONFIG_FILES[@]}"; do
    TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
    if [ -f "$config_file" ]; then
        PERMS=$(stat -c "%a" "$config_file")
        if [ "$PERMS" = "600" ]; then
            log "  ✓ Config file exists with secure permissions (600): $(basename $config_file)"
            PASSED_CHECKS=$((PASSED_CHECKS + 1))
        else
            log "  ⚠ Config file exists but permissions not 600: $(basename $config_file) ($PERMS)"
            WARNING_CHECKS=$((WARNING_CHECKS + 1))
        fi
    else
        log "  ✗ Missing config file: $config_file"
        FAILED_CHECKS=$((FAILED_CHECKS + 1))
    fi
done
log ""

# Section 9: API Health Check
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "9. API Health Check"
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
if curl -s -f http://localhost:8000/api/health > /dev/null 2>&1; then
    log "  ✓ API health endpoint accessible"
    PASSED_CHECKS=$((PASSED_CHECKS + 1))

    # Show API response
    log ""
    log "  API Health Response:"
    curl -s http://localhost:8000/api/health | python3 -m json.tool 2>/dev/null | head -20 || log "     (could not parse JSON)"
    log ""
else
    log "  ✗ API health endpoint not accessible"
    log "     API may not be running or still starting"
    FAILED_CHECKS=$((FAILED_CHECKS + 1))
fi
log ""

# Section 10: Recent Data Check
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "10. Recent Data Check"
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

# Check for SPY symbol
TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
SPY_COUNT=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM symbols WHERE symbol = 'SPY';" 2>/dev/null | xargs || echo "0")
if [ "$SPY_COUNT" -gt 0 ]; then
    log "  ✓ SPY symbol configured"
    PASSED_CHECKS=$((PASSED_CHECKS + 1))
else
    log "  ⚠ SPY symbol not yet configured"
    log "     Add with: make psql, then INSERT INTO symbols..."
    WARNING_CHECKS=$((WARNING_CHECKS + 1))
fi

# Check for recent data
TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
RECENT_DATA=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM underlying_quotes WHERE timestamp > NOW() - INTERVAL '1 hour';" 2>/dev/null | xargs || echo "0")
if [ "$RECENT_DATA" -gt 0 ]; then
    log "  ✓ Recent data found: $RECENT_DATA rows (last hour)"
    PASSED_CHECKS=$((PASSED_CHECKS + 1))
else
    log "  ⚠ No recent data (normal if just started or market closed)"
    WARNING_CHECKS=$((WARNING_CHECKS + 1))
fi
log ""

# Section 11: Service Logs
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "11. Recent Service Logs (Last 5 lines)"
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log ""
log "Ingestion Service:"
sudo journalctl -u zerogex-oa-ingestion -n 5 --no-pager || log "  (no logs yet)"
log ""
log "Analytics Service:"
sudo journalctl -u zerogex-oa-analytics -n 5 --no-pager || log "  (no logs yet)"
log ""
log "API Service:"
sudo journalctl -u zerogex-oa-api -n 5 --no-pager || log "  (no logs yet)"
log ""

# Final Summary
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log "VALIDATION SUMMARY"
log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
log ""
log "Total Checks: $TOTAL_CHECKS"
log "Passed: $PASSED_CHECKS"
log "Warnings: $WARNING_CHECKS"
log "Failed: $FAILED_CHECKS"
log ""

if [ "$FAILED_CHECKS" -eq 0 ]; then
    log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    log "✓ Deployment validation PASSED!"
    log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    log ""
    log "ZeroGEX-OA platform is ready!"

    if [ "$WARNING_CHECKS" -gt 0 ]; then
        log ""
        log "Note: Some warnings detected (normal for fresh deployment)"
        log "  • SPY symbol can be added via: make psql"
        log "  • Recent data will appear when markets open and services run"
    fi
else
    log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    log "✗ Deployment validation FAILED!"
    log "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    log ""
    log "Please review failed checks and resolve issues."
    log ""
    log "Common issues:"
    log "  • RDS security group not allowing EC2 connections"
    log "  • Incorrect RDS credentials in .pgpass"
    log "  • TradeStation API credentials not configured"
    log "  • Python packages not installed correctly"
    log "  • API service not running (check: sudo systemctl status zerogex-oa-api)"
    exit 1
fi

log ""
log "Next Steps:"
log "  1. Add SPY symbol (if not already done)"
log "  2. Monitor services: make ingestion-logs, make analytics-logs, make api-logs"
log "  3. Check data flow: make stats"
log "  4. Test API: make api-test"
log "  5. View API docs: http://localhost:8000/docs"
log ""
log "Deployment validation complete!"
log ""
